{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a94509",
   "metadata": {},
   "source": [
    "\n",
    "# NBA Top-150: Stat Distributions & Summary (Plain Notebook)\n",
    "\n",
    "This notebook:\n",
    "- Loads a per-game CSV (e.g., `nba_top_150_per_game_24_25.csv`)\n",
    "- Detects key stat columns (PTS, REB, AST, STL, BLK, TOV, 3PM, FG%, FT%)\n",
    "- Computes **mean, median, ±1 SD**, plus min/max and quartiles\n",
    "- Saves a summary CSV\n",
    "- Plots distributions (histograms) with mean and ±1 SD vertical lines\n",
    "\n",
    "> Edit the **Configuration** cell below to set your CSV path and output folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Configuration ===\n",
    "CSV_PATH = \"data/processed/nba_top_150_per_game_24_25.csv\"   # <-- change to your file location\n",
    "OUTDIR = Path(\"outputs\")                                     # where to save summary & figures\n",
    "BINS = 20                                                    # histogram bins\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e49f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {CSV_PATH!r} with shape {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STAT_NAME_ALIASES = {\n",
    "    \"PTS\": [\"PTS\"],\n",
    "    \"REB\": [\"REB\", \"TRB\"],\n",
    "    \"AST\": [\"AST\"],\n",
    "    \"STL\": [\"STL\"],\n",
    "    \"BLK\": [\"BLK\"],\n",
    "    \"TOV\": [\"TOV\", \"TO\"],\n",
    "    \"3PM\": [\"3PM\", \"FG3M\", \"3P\"],\n",
    "    \"FG%\": [\"FG%\", \"FG_PCT\"],\n",
    "    \"FT%\": [\"FT%\", \"FT_PCT\"],\n",
    "    # \"GP\": [\"GP\"],\n",
    "    # \"MIN\": [\"MIN\"],\n",
    "}\n",
    "\n",
    "def pick_present_columns(df: pd.DataFrame) -> dict:\n",
    "    actual = {}\n",
    "    lower_cols = {c.lower(): c for c in df.columns}\n",
    "    for logical, candidates in STAT_NAME_ALIASES.items():\n",
    "        for cand in candidates:\n",
    "            if cand.lower() in lower_cols:\n",
    "                actual[logical] = lower_cols[cand.lower()]\n",
    "                break\n",
    "    return actual\n",
    "\n",
    "def summarize_stats(df: pd.DataFrame, col_map: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for logical, col in col_map.items():\n",
    "        series = pd.to_numeric(df[col], errors=\"coerce\").dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"stat\": logical,\n",
    "            \"column\": col,\n",
    "            \"count\": int(series.count()),\n",
    "            \"mean\": float(series.mean()),\n",
    "            \"median\": float(series.median()),\n",
    "            \"std\": float(series.std(ddof=1)),\n",
    "            \"min\": float(series.min()),\n",
    "            \"max\": float(series.max()),\n",
    "            \"p25\": float(series.quantile(0.25)),\n",
    "            \"p75\": float(series.quantile(0.75)),\n",
    "        })\n",
    "    out = pd.DataFrame(rows).sort_values(\"stat\").reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930165e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_map = pick_present_columns(df)\n",
    "if not col_map:\n",
    "    raise RuntimeError(\"No expected stat columns found. Check your CSV headers or STAT_NAME_ALIASES.\")\n",
    "\n",
    "summary = summarize_stats(df, col_map)\n",
    "\n",
    "print(\"\\n=== Summary (mean, median, ±1 SD) ===\\n\")\n",
    "for _, row in summary.iterrows():\n",
    "    print(f\"{row['stat']:>4}  mean={row['mean']:.3f}  median={row['median']:.3f}  std={row['std']:.3f}  (n={row['count']})\")\n",
    "print()\n",
    "\n",
    "summary_path = OUTDIR / \"stat_distributions_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(f\"Saved summary → {summary_path}\")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb40180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figs_dir = OUTDIR / \"figures\"\n",
    "figs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for logical, col in col_map.items():\n",
    "    series = pd.to_numeric(df[col], errors=\"coerce\").dropna()\n",
    "    if series.empty:\n",
    "        continue\n",
    "\n",
    "    mean = series.mean()\n",
    "    std = series.std(ddof=1)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.hist(series, bins=BINS, edgecolor=\"black\")\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=1.5, label=f\"Mean = {mean:.3f}\")\n",
    "    if np.isfinite(std) and std > 0:\n",
    "        plt.axvline(mean - std, linestyle=\":\", linewidth=1.2, label=f\"Mean - 1 SD = {mean - std:.3f}\")\n",
    "        plt.axvline(mean + std, linestyle=\":\", linewidth=1.2, label=f\"Mean + 1 SD = {mean + std:.3f}\")\n",
    "\n",
    "    plt.title(f\"Distribution of {logical} ({col})\")\n",
    "    plt.xlabel(logical)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outpath = figs_dir / f\"hist_{logical.replace('%','pct')}.png\"\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Saved histograms → {figs_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b653e",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "- Include GP/MIN by uncommenting them in `STAT_NAME_ALIASES`.\n",
    "- If your CSV headers differ, add aliases.\n",
    "- Increase `BINS` for smoother histograms.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}